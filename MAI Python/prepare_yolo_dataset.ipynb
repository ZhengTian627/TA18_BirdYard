{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44928df0-2622-43f1-a63c-4ed56a0b37c1",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef8dac7-d9ba-4a07-9d67-5f5d658e55a6",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b932236-af20-403a-b8f5-49bc4d8338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml # PyYAML: pip install pyyaml\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c3398-95da-4c86-bb03-540e8af456b0",
   "metadata": {},
   "source": [
    "## Divide image dataset into training and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb089824-d5ff-428b-b54d-5045f2e804ed",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566aa4b3-a4e7-4c04-b137-d69e0912d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PATHS\n",
    "# Path to the directory containing species folders\n",
    "INPUT_BASE_DIR = Path(\"./images\") \n",
    "\n",
    "# Path where the structured YOLO dataset will be created\n",
    "OUTPUT_BASE_DIR = Path(\"./datasets/bird_dataset_yolo\")\n",
    "\n",
    "# 2. DATASET PARAMETERSà¸\n",
    "# Define species and assign class IDs (MUST start from 0)\n",
    "CLASS_MAPPING = {\n",
    "    \"Australasian_Bittern\": 0,\n",
    "    \"Australian_Painted_Snipe\": 1,\n",
    "    \"Gang-gang_Cockatoo\":2,\n",
    "    \"Grey_Falcon\":3,\n",
    "    \"Painted_Honeyeater\":4,\n",
    "    \"Pilotbird\":5,\n",
    "    \"Plains_Wanderer\":6,\n",
    "    \"Southern_Whiteface\":7,\n",
    "    \"Swift_Parrot\":8,\n",
    "    \"White-throated_Needletail\":9\n",
    "}\n",
    "\n",
    "# Define the split ratio for training data (e.g., 0.8 means 80% train, 20% val)\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Allowed image extensions\n",
    "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
    "\n",
    "def create_yolo_label_file(label_path, class_id):\n",
    "    \"\"\"\n",
    "    Creates a YOLO format label file assuming the object covers the whole image.\n",
    "    \"\"\"\n",
    "    # Format: class_id center_x center_y width height (normalized)\n",
    "    yolo_line = f\"{class_id} 0.5 0.5 1.0 1.0\\n\"\n",
    "    try:\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(yolo_line)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error writing label file {label_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea75de-c88e-433a-bdaa-303e4a2db149",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4350eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset preparation...\n",
      "Created directory: datasets\\bird_dataset_yolo\\images\\train\n",
      "Created directory: datasets\\bird_dataset_yolo\\labels\\train\n",
      "Created directory: datasets\\bird_dataset_yolo\\images\\val\n",
      "Created directory: datasets\\bird_dataset_yolo\\labels\\val\n",
      "\n",
      "Processing species folders...\n",
      "\n",
      "Processing species: 'Australasian_Bittern' (Class ID: 0)\n",
      "  Input directory: images\\Australasian_Bittern\n",
      "  Found 74 images for this species.\n",
      "  Splitting into 59 train and 15 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Australian_Painted_Snipe' (Class ID: 1)\n",
      "  Input directory: images\\Australian_Painted_Snipe\n",
      "  Found 45 images for this species.\n",
      "  Splitting into 36 train and 9 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Gang-gang_Cockatoo' (Class ID: 2)\n",
      "  Input directory: images\\Gang-gang_Cockatoo\n",
      "  Found 398 images for this species.\n",
      "  Splitting into 318 train and 80 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Grey_Falcon' (Class ID: 3)\n",
      "  Input directory: images\\Grey_Falcon\n",
      "  Found 44 images for this species.\n",
      "  Splitting into 35 train and 9 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Painted_Honeyeater' (Class ID: 4)\n",
      "  Input directory: images\\Painted_Honeyeater\n",
      "  Found 104 images for this species.\n",
      "  Splitting into 83 train and 21 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Pilotbird' (Class ID: 5)\n",
      "  Input directory: images\\Pilotbird\n",
      "  Found 64 images for this species.\n",
      "  Splitting into 51 train and 13 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Plains_Wanderer' (Class ID: 6)\n",
      "  Input directory: images\\Plains_Wanderer\n",
      "  Found 21 images for this species.\n",
      "  Splitting into 16 train and 5 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Southern_Whiteface' (Class ID: 7)\n",
      "  Input directory: images\\Southern_Whiteface\n",
      "  Found 232 images for this species.\n",
      "  Splitting into 185 train and 47 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'Swift_Parrot' (Class ID: 8)\n",
      "  Input directory: images\\Swift_Parrot\n",
      "  Found 106 images for this species.\n",
      "  Splitting into 84 train and 22 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processing species: 'White-throated_Needletail' (Class ID: 9)\n",
      "  Input directory: images\\White-throated_Needletail\n",
      "  Found 88 images for this species.\n",
      "  Splitting into 70 train and 18 validation images.\n",
      "  Processing training set...\n",
      "  Processing validation set...\n",
      "\n",
      "Processed 1176 total images.\n",
      "  Training images: 937\n",
      "  Validation images: 239\n",
      "\n",
      "Creating data.yaml file...\n",
      "Successfully created data.yaml at: datasets\\bird_dataset_yolo\\data.yaml\n",
      "\n",
      "Dataset preparation finished!\n",
      "YOLO dataset structure created at: datasets\\bird_dataset_yolo\n"
     ]
    }
   ],
   "source": [
    "# Begin dividing image dataset into training and validation datasets\n",
    "print(\"Starting dataset preparation...\")\n",
    "\n",
    "# 1. Create Output Directories\n",
    "img_train_dir = OUTPUT_BASE_DIR / \"images\" / \"train\"\n",
    "lbl_train_dir = OUTPUT_BASE_DIR / \"labels\" / \"train\"\n",
    "img_val_dir = OUTPUT_BASE_DIR / \"images\" / \"val\"\n",
    "lbl_val_dir = OUTPUT_BASE_DIR / \"labels\" / \"val\"\n",
    "\n",
    "for dir_path in [img_train_dir, lbl_train_dir, img_val_dir, lbl_val_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "total_images_processed = 0\n",
    "total_train_images = 0\n",
    "total_val_images = 0\n",
    "\n",
    "# 2. Process Each Species Folder\n",
    "print(\"\\nProcessing species folders...\")\n",
    "for species_name, class_id in CLASS_MAPPING.items():\n",
    "    species_input_dir = INPUT_BASE_DIR / species_name\n",
    "    print(f\"\\nProcessing species: '{species_name}' (Class ID: {class_id})\")\n",
    "    print(f\"  Input directory: {species_input_dir}\")\n",
    "\n",
    "    if not species_input_dir.is_dir():\n",
    "        print(f\"  Warning: Input directory not found for '{species_name}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get all image files for the current species\n",
    "    image_files = [f for f in species_input_dir.iterdir() if f.is_file() and f.suffix.lower() in IMAGE_EXTENSIONS]\n",
    "    num_images = len(image_files)\n",
    "    print(f\"  Found {num_images} images for this species.\")\n",
    "\n",
    "    if num_images == 0:\n",
    "        print(\"  No images found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Shuffle the image files randomly\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Calculate split index\n",
    "    split_index = int(num_images * TRAIN_RATIO)\n",
    "    train_files = image_files[:split_index]\n",
    "    val_files = image_files[split_index:]\n",
    "\n",
    "    print(f\"  Splitting into {len(train_files)} train and {len(val_files)} validation images.\")\n",
    "\n",
    "    # Process Training Files\n",
    "    print(\"  Processing training set...\")\n",
    "    for img_path in train_files:\n",
    "        try:\n",
    "            # Copy image\n",
    "            dest_img_path = img_train_dir / img_path.name\n",
    "            shutil.copy2(img_path, dest_img_path) # copy2 preserves metadata\n",
    "\n",
    "            # Create label file\n",
    "            label_filename = img_path.stem + \".txt\"\n",
    "            dest_lbl_path = lbl_train_dir / label_filename\n",
    "            create_yolo_label_file(dest_lbl_path, class_id)\n",
    "\n",
    "            total_train_images += 1\n",
    "            total_images_processed +=1\n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {img_path.name} for training: {e}\")\n",
    "\n",
    "\n",
    "    # Process Validation Files\n",
    "    print(\"  Processing validation set...\")\n",
    "    for img_path in val_files:\n",
    "        try:\n",
    "            # Copy image\n",
    "            dest_img_path = img_val_dir / img_path.name\n",
    "            shutil.copy2(img_path, dest_img_path)\n",
    "\n",
    "            # Create label file\n",
    "            label_filename = img_path.stem + \".txt\"\n",
    "            dest_lbl_path = lbl_val_dir / label_filename\n",
    "            create_yolo_label_file(dest_lbl_path, class_id)\n",
    "\n",
    "            total_val_images += 1\n",
    "            total_images_processed +=1\n",
    "        except Exception as e:\n",
    "             print(f\"    Error processing {img_path.name} for validation: {e}\")\n",
    "\n",
    "print(f\"\\nProcessed {total_images_processed} total images.\")\n",
    "print(f\"  Training images: {total_train_images}\")\n",
    "print(f\"  Validation images: {total_val_images}\")\n",
    "\n",
    "# 3. Create data.yaml file\n",
    "print(\"\\nCreating data.yaml file...\")\n",
    "yaml_path = OUTPUT_BASE_DIR / \"data.yaml\"\n",
    "\n",
    "# Create the 'names' list in the correct order of class IDs\n",
    "names_list = [name for name, idx in sorted(CLASS_MAPPING.items(), key=lambda item: item[1])]\n",
    "\n",
    "yaml_content = {\n",
    "    'path': str(OUTPUT_BASE_DIR.resolve()), # Absolute path recommended by Ultralytics\n",
    "    'train': str((OUTPUT_BASE_DIR / \"images\" / \"train\").relative_to(OUTPUT_BASE_DIR)), #'images/train',\n",
    "    'val': str((OUTPUT_BASE_DIR / \"images\" / \"val\").relative_to(OUTPUT_BASE_DIR)), #'images/val',\n",
    "    'nc': len(CLASS_MAPPING),\n",
    "    # 'test': '', # Add if you create a test set\n",
    "    'names': names_list\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f, sort_keys=False, default_flow_style=False)\n",
    "    print(f\"Successfully created data.yaml at: {yaml_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating data.yaml: {e}\")\n",
    "\n",
    "print(\"\\nDataset preparation finished!\")\n",
    "print(f\"YOLO dataset structure created at: {OUTPUT_BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f30419-1095-42a3-9952-f310b2a73f67",
   "metadata": {},
   "source": [
    "## Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28300af3-35da-4b0a-8d89-91a4559118ff",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01426eac-6d50-4730-ae1b-147700806d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the base directory of your YOLO dataset\n",
    "DATASET_BASE_DIR = Path(\"./datasets/bird_dataset_yolo\")\n",
    "\n",
    "# Target size (width and height) for resizing\n",
    "TARGET_SIZE = 320 # (e.g., 320 or 416)\n",
    "\n",
    "# Subdirectories containing images to resize\n",
    "IMAGE_SUBDIRS = [\"train\", \"val\"] # Add \"test\" if you have it\n",
    "\n",
    "# Allowed image extensions\n",
    "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
    "\n",
    "def resize_image(image_path, target_size):\n",
    "    \"\"\"Reads, resizes, and overwrites an image file.\"\"\"\n",
    "    try:\n",
    "        # Ensure the path is treated as a string for OpenCV functions\n",
    "        img_path_str = str(image_path)\n",
    "\n",
    "        img = cv2.imread(img_path_str)\n",
    "        if img is None:\n",
    "            # This error is now explicitly caught and reported in main\n",
    "            return False, f\"Could not read image {image_path.name}\"\n",
    "\n",
    "        # Get original dimensions (optional, for info)\n",
    "        # original_height, original_width = img.shape[:2]\n",
    "\n",
    "        # Resize the image - cv2.resize expects (width, height)\n",
    "        # cv2.INTER_AREA is generally recommended for shrinking images\n",
    "        resized_img = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Overwrite the original file\n",
    "        success = cv2.imwrite(img_path_str, resized_img)\n",
    "        if not success:\n",
    "             # This error is now explicitly caught and reported in main\n",
    "             return False, f\"Failed to write resized image {image_path.name}\"\n",
    "\n",
    "        # print(f\"    Resized {image_path.name} from {original_width}x{original_height} to {target_size}x{target_size}\")\n",
    "        return True, None # Success, no error message\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors during processing\n",
    "        return False, f\"Error processing {image_path.name}: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0a8a0-59b6-4555-b62a-0ba746c9f61b",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c994c2d-7ec0-400b-8e0a-fde177be7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting image resizing process...\n",
      "Target size: 320x320\n",
      "Dataset base directory: datasets\\bird_dataset_yolo\n",
      "\n",
      " WARNING: This script will overwrite original images in place! \n",
      "Make sure you have a backup if needed.\n",
      "\n",
      "Processing directory: datasets\\bird_dataset_yolo\\images\\train\n",
      "  Found 937 images.\n",
      "  Processing image 937/937: White-throated Needletail (Hirundapus caudacutus)_v9.jpg......\n",
      "  Finished processing directory: datasets\\bird_dataset_yolo\\images\\train\n",
      "\n",
      "Processing directory: datasets\\bird_dataset_yolo\\images\\val\n",
      "  Found 239 images.\n",
      "  Processing image 239/239: White-throated Needletail (Hirundapus caudacutus)_v8.jpg......\n",
      "  Finished processing directory: datasets\\bird_dataset_yolo\\images\\val\n",
      "\n",
      "--- Resizing Summary ---\n",
      "Successfully processed and resized: 1176 images\n",
      "Failed to process:                 0 images\n",
      "\n",
      "No files failed during processing.\n",
      "\n",
      "Total time taken:                  19.25 seconds\n",
      "Image resizing complete.\n"
     ]
    }
   ],
   "source": [
    "# Begin resizing images\n",
    "print(\"Starting image resizing process...\")\n",
    "print(f\"Target size: {TARGET_SIZE}x{TARGET_SIZE}\")\n",
    "print(f\"Dataset base directory: {DATASET_BASE_DIR}\")\n",
    "print(\"\\n WARNING: This script will overwrite original images in place! \")\n",
    "print(\"Make sure you have a backup if needed.\")\n",
    "time.sleep(3) # Pause for 3 seconds to allow cancellation\n",
    "\n",
    "images_processed = 0\n",
    "images_failed = 0\n",
    "failed_files_details = [] # List to store details of failed files\n",
    "start_time = time.time()\n",
    "\n",
    "images_root_dir = DATASET_BASE_DIR / \"images\"\n",
    "\n",
    "for subdir_name in IMAGE_SUBDIRS:\n",
    "    current_dir = images_root_dir / subdir_name\n",
    "    print(f\"\\nProcessing directory: {current_dir}\")\n",
    "\n",
    "    if not current_dir.is_dir():\n",
    "        print(f\"  Warning: Subdirectory '{subdir_name}' not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    image_files = [f for f in current_dir.iterdir() if f.is_file() and f.suffix.lower() in IMAGE_EXTENSIONS]\n",
    "    num_images = len(image_files)\n",
    "    print(f\"  Found {num_images} images.\")\n",
    "\n",
    "    if num_images == 0:\n",
    "        continue # Skip if no images found\n",
    "\n",
    "    for i, img_path in enumerate(image_files):\n",
    "        # Update progress indicator on the same line\n",
    "        print(f\"  Processing image {i+1}/{num_images}: {img_path.name}...\", end='\\r', flush=True)\n",
    "\n",
    "        success, error_msg = resize_image(img_path, TARGET_SIZE)\n",
    "\n",
    "        if success:\n",
    "            images_processed += 1\n",
    "        else:\n",
    "            images_failed += 1\n",
    "            # Store the path and the error message for reporting\n",
    "            failed_files_details.append({'path': str(img_path), 'error': error_msg})\n",
    "            # Print the specific error immediately when it occurs, on a new line\n",
    "            print(f\"\\n    ERROR: {error_msg}\") # Print error immediately\n",
    "\n",
    "    # Clear the progress indicator line after finishing a directory\n",
    "    print(f\"\\n  Finished processing directory: {current_dir}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resizing Summary ---\")\n",
    "print(f\"Successfully processed and resized: {images_processed} images\")\n",
    "print(f\"Failed to process:                 {images_failed} images\")\n",
    "\n",
    "# --- Report Failed Files ---\n",
    "if failed_files_details:\n",
    "    print(\"\\n--- Failed File Details ---\")\n",
    "    print(\"The following image files could not be processed and may need review or removal:\")\n",
    "    for item in failed_files_details:\n",
    "        print(f\"  - Path:  {item['path']}\")\n",
    "        print(f\"    Error: {item['error']}\")\n",
    "        # Suggestion for removal command (use with caution!)\n",
    "        # print(f\"    (To remove on Linux/macOS: rm \\\"{item['path']}\\\")\")\n",
    "        # print(f\"    (To remove on Windows: del \\\"{item['path']}\\\")\")\n",
    "    print(\"\\nConsider checking these files for corruption or unsupported formats.\")\n",
    "elif images_failed > 0:\n",
    "     print(\"\\nNOTE: Some files failed, but details were not captured (check script logic).\")\n",
    "else:\n",
    "     print(\"\\nNo files failed during processing.\")\n",
    "# --- End Report ---\n",
    "\n",
    "print(f\"\\nTotal time taken:                  {duration:.2f} seconds\")\n",
    "print(\"Image resizing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec63177-8876-405e-81b3-8e0694c1da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CLASS_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90843deb-bffd-459a-a39c-28ac10ce6e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
